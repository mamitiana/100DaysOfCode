{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Day 2: 100 days of Daily Coding!\n",
    "\n",
    "Happy Sunday!\n",
    "\n",
    "Today,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fH113x7XbyQ6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction for the input x\n",
      "tensor([[ 61.5000,  72.1080],\n",
      "        [ 84.5488, 100.0979],\n",
      "        [106.3992, 131.3717],\n",
      "        [ 45.8068,  46.1537],\n",
      "        [ 91.6490, 113.0400]], grad_fn=<AddBackward0>)\n",
      "loss  tensor(102.4455, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "class LinearRegressionModel():\n",
    "    def __init__(self,X , y):\n",
    "        ''' X , y are np array '''\n",
    "        self.inputs = torch.from_numpy(X)\n",
    "        self.targets = torch.from_numpy(y)\n",
    "        self.weight = torch.randn(y.shape[1] , X.shape[1],requires_grad=True )\n",
    "        self.bias = torch.randn( y.shape[1] , requires_grad=True)\n",
    "    def fit(self,epoch):\n",
    "        # y = w X + b  (w and b are the our hyperparameter to optimise)\n",
    "        '''\n",
    "        the fit is gradient descent algorthim.We update the hyperparameter (w and b) on each steps in the algorithms.\n",
    "        '''\n",
    "        for i in range(epoch):\n",
    "            preds = self.predict(self.inputs , is_tensor=True)\n",
    "            loss = self.mse( preds , self.targets )\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                self.weight -= self.weight.grad* 1e-5\n",
    "                self.bias -= self.bias.grad* 1e-5\n",
    "                self.weight.grad.zero_()\n",
    "                self.bias.grad.zero_()      \n",
    "    def predict(self,X , is_tensor = False):\n",
    "        if is_tensor==False:\n",
    "            X = torch.from_numpy(X)\n",
    "        return X @ self.weight.t()  + self.bias\n",
    "    def mse(self,ypred,  yreal):\n",
    "        ''' mean squared error, ypred and yreal are tensor  '''\n",
    "        diff = ypred - yreal\n",
    "        return torch.sum(diff*diff ) /diff.numel()\n",
    "inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70]], dtype='float32')\n",
    "targets = np.array([[56, 70], [81, 101], [119, 133], [22, 37],  [103, 119]], dtype='float32')\n",
    "lm = LinearRegressionModel(inputs , targets)\n",
    "lm.fit(200)\n",
    "prediction = lm.predict(inputs)\n",
    "print('prediction for the input x')\n",
    "print(prediction)\n",
    "calculatedLoss = lm.mse( prediction, torch.from_numpy(targets) )\n",
    "print('loss ',calculatedLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "day2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
